对应流畅的python第三章内容
# 字典
## 映射
字典的内部实现，与数学中的映射十分类似，或者可以说就是映射。这里可以引入一个内置函数[map](https://docs.python.org/3/library/functions.html?highlight=map#map)，从某种程度上理解，十分相似。在查看字节码时也能证明，字典的思想就是映射。
```python 
import dis
print(dis.dis('x={ abc: 1}'))

  1           0 LOAD_NAME                0 (abc)
              2 LOAD_CONST               0 (1)
           *  4 BUILD_MAP                1
              6 STORE_NAME               1 (x)
              8 LOAD_CONST               1 (None)
             10 RETURN_VALUE
```
那么字典的映射关系就是：键->值，就像我们在python中使用字典时一样，我们通过字典的特定键，返回他们的值，而不是返回一个键值对。
```python
>>> test_dict = {'a': 1}
>>> test_dict['a']
1
```
除此之外，仍有一些字典内容的扩展，形成新的类，它们与字典统称为**映射类***(后文会单独解释映射类，并且其他地方仍然用字典类来描述字典)
## 创建
首先来看一个字典类的方法
```python
>>> dir(test_dict)
['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', **'__hash__'**, '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']
```
我标记了一个方法：`__hash__`，学过算法的人对`__hash__`会比较熟悉，它可以被视为创建散列表，在牺牲存储空间的同时提升算法性能。 ^85df98
## 以下是意义不明的一段，只需要知道字典的键是通过做哈希来保证唯一性的就可以
下面来实际看一下CPython中，如何实现的哈希表。这部分可能跳过，只需要知道字典很快就可以了。
```c++
typedef struct {
    PyObject_HEAD

    /* Number of items in the dictionary */
    Py_ssize_t ma_used;

    /* Dictionary version: globally unique, value change each time
       the dictionary is modified */
    uint64_t ma_version_tag;

    PyDictKeysObject *ma_keys;

    /* If ma_values is NULL, the table is "combined": keys and values
       are stored in ma_keys.
       If ma_values is not NULL, the table is splitted:
       keys are stored in ma_keys and values are stored in ma_values */
    PyObject **ma_values;
} PyDictObject;
```
这里还提到，字典从存储形式上可以分为"combined"或"splitted"形式，分别对应键值对是否储存在一起。
PyDictKeysObject：
```c++
struct _dictkeysobject {
    Py_ssize_t dk_refcnt;

    /* Size of the hash table (dk_indices). It must be a power of 2. */
    Py_ssize_t dk_size;

    /* Function to lookup in the hash table (dk_indices):
       - lookdict(): general-purpose, and may return DKIX_ERROR if (and
         only if) a comparison raises an exception.
       - lookdict_unicode(): specialized to Unicode string keys, comparison of
         which can never raise an exception; that function can never return
         DKIX_ERROR.
       - lookdict_unicode_nodummy(): similar to lookdict_unicode() but further
         specialized for Unicode string keys that cannot be the <dummy> value.
       - lookdict_split(): Version of lookdict() for split tables. */
    dict_lookup_func dk_lookup;

    /* Number of usable entries in dk_entries. */
    Py_ssize_t dk_usable;

    /* Number of used entries in dk_entries. */
    Py_ssize_t dk_entries;

    /* Actual hash table of dk_size entries. It holds indices in dk_entries,
       or DKIX_EMPTY(-1) or DKIX_DUMMY(-2).
       Indices must be: 0 <= indice < USABLE_FRACTION(dk_size).
       The size in bytes of an indice depends on dk_size:
       - 1 byte if dk_size <= 0xff (char*)
       - 2 bytes if dk_size <= 0xffff (int16_t*)
       - 4 bytes if dk_size <= 0xffffffff (int32_t*)
       - 8 bytes otherwise (int64_t*)
       Dynamically sized, 8 is minimum. */
    union {
        int8_t as_1[8];
        int16_t as_2[4];
        int32_t as_4[2];
#if SIZEOF_VOID_P > 4
        int64_t as_8[1];
#endif
    } dk_indices;
	/*  the past version:
   	char dk_indices[];  */ 
	

    /* "PyDictKeyEntry dk_entries[dk_usable];" array follows:
       see the DK_ENTRIES() macro */
};
```
`dk_indices`和`dk_size`是配套使用的，`dk_size`保存整个字典的长度的二进制，然后在`dk_indices`的union中选择合适的位数。从命名上也容易知道，`dk_indices`实际上保存的是**索引**，随着索引的增多，二进制会出现增位现象，而一开始设置成最长长度又消耗内存，就采取了动态选择方法。`dk_indices`的内部也应该就是一个个索引的二进制。整个字典的保存方式
![](https://raw.githubusercontent.com/byueng/images/master/20230123223332.png)

`dk_entries`中每一个元素称为一个`entry`，是一个`PyDictKeyEntry`对象，定义在`Object/dict-common.h`中：

```c++
typedef struct {
    /* Cached hash code of me_key. */
    Py_hash_t me_hash;
    PyObject *me_key;
    PyObject *me_value; /* This field is only meaningful for combined tables */
} PyDictKeyEntry;
```
	看这段源码的初衷是想看一下，在哈希表中的查找算法与列表的遍历算法在底层的逻辑上是否存在差别，很遗憾没有找到，网上的说法是哈希的平均时间复杂度是O(1)，而列表是O(n)，如果有懂哥可以联系我深入了解下。
## 散列表(Hash tabel)
这部分开始就是字典的特性。字典的键是唯一的，而区别它们的方法就是hash，哈希表又名散列表，维基百科中对其有相关的描述：[散列表](https://zh.m.wikipedia.org/zh-sg/%E5%93%88%E5%B8%8C%E8%A1%A8)

> [!NOTE] Title
> 我一直以为散列表跟哈希表之间的关系是一个包含于另一个的，直到我在维基百科里发信散列表的英文就是Hash tabel

## 字典的tips
我在曾经一个代码书写上有个这样的需求：查找某一个键，如果没有就新建一个键值对，附上值，如果存在，将值改变成我想要的，然后直接返回值。我记得很清楚当时我用的是`get`，也能够比较好的实现。做一个返回值判断就可以了。这里介绍一个内置的方法`setfault(k, [default])`,若字典里有键k，则把它对应的值设置为default，然后返回这个值，如果没有，先设置`d[k] = default`，然后返回default。

## 特殊方法`__missing__`
所有映射类型在找不到键时都会调用这个方法，但是却无法在解析基类时找到它，但是却能重写它以达到在字典找不到键时，需要的一些逻辑。

## 字典的一些变种
- collections.OrderedDict
- collections.ChainMap
- collections.Counter
- collections.UserDict
这些变种的提供为我们在实现字典需求时，节省下部分时间。

# 集合
集合也是散列表
集合的最大的用途之一是去重，因为散列表的原因，集合保证了其内部的元素不会重复。它可以用来对序列去重，进行统计等。
```python
>>> uht = [1, 2, 3, 1, 2, 3]
>>> uht
[1, 2, 3, 1, 2, 3]
>>> ht = set(uht)
>>> ht
{1, 2, 3}
```

## 创建陷阱
序列的创建方式都是不只有一种的。
如果想要创建一个**空的集合**,必须用`set()`而不是`{}`来创建，这样会与字典冲突，而且会创建一个空字典。
```python
>>> eht = {}
>>> type(eht)
<class 'dict'>
```

## 集合论
正如其名，python的集合类型与数学上的集合也有共同的地方，甚至也支持了各种集合运算，比如`in, <=, >, >=, ...`
```python
import pandas as pd

df1 = pd.read_excel("./file1.xlsx").loc[:, "姓名"]
df2 = pd.read_excel("./file2.xlsx").loc[:, "姓名"]

no_sign_up = set(df1) - set(df2)
```
实例： 利用集合快速筛查报名信息

## 到底有多快？
![IMG_20230202_153347.jpg](https://raw.githubusercontent.com/byueng/images/master/a%20test%20about%20effient.jpg)
haystack是一个装有双精度浮点数的数组，然后进行查找实验并记录运行时间。